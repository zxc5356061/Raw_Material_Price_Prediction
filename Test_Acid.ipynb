{"cells":[{"source":"# Test_Acid","metadata":{},"cell_type":"markdown","id":"a62679b9-b669-4eb6-859d-fdfbee54ba8f"},{"source":"!pip install fredapi","metadata":{"executionCancelledAt":null,"executionTime":5665,"lastExecutedAt":1715012970709,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install fredapi","outputsMetadata":{"0":{"height":332,"type":"stream"}},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":false}},"cell_type":"code","id":"470a342d-66ac-46e2-a8e6-bc5a976d1e81","outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: fredapi in /home/repl/.local/lib/python3.10/site-packages (0.5.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fredapi) (2.2.1)\nRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fredapi) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->fredapi) (1.16.0)\n"}],"execution_count":1},{"source":"import preprocessor as pre\nimport visualiser as visual\nimport pandas as pd\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n## Preparations\n# Import data\ngas_df = pre.get_Fred_data('PNGASEUUSDM',2014,2024)\nwheat_df = pre.get_Fred_data('PWHEAMTUSDM',2014,2024)\nammonia_df = pre.get_Fred_data('WPU0652013A',2014,2024)\nelec_df = pre.clean_elec_csv('Data_flat_files/ELECTRICITY_03_2024.csv',2014,2024)\n\ndf = pre.clean_pred_price_evo_csv(\"Data_flat_files/Dataset_Future_Predicting_Price_Evolutions_202403.csv\",2014,2023)\n\ntarget = 'acid'.lower()\n\nRM_codes = ['RM01/0001','RM01/0004','RM01/0006','RM01/0007']\n\nexternal_drivers = {\n    \"PNGASEUUSDM\": gas_df,\n    \"PWHEAMTUSDM\": wheat_df,\n    \"WPU0652013A\": ammonia_df,\n    \"Electricity\": elec_df\n}\n\ntest_periods = [\n    ('2020-01-01', '2020-07-01'),\n    ('2020-07-01', '2021-01-01'),\n    ('2021-01-01', '2021-07-01'),\n    ('2021-07-01', '2022-01-01'),\n    ('2022-01-01', '2022-07-01'),\n    ('2022-07-01', '2023-01-01'),\n    ('2023-01-01', '2023-07-01'),\n    ('2023-07-01', '2024-01-01')\n]\n\nlags = [1,3,6]","metadata":{"executionCancelledAt":null,"executionTime":2340,"lastExecutedAt":1715012973051,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import preprocessor as pre\nimport visualiser as visual\nimport pandas as pd\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n## Preparations\n# Import data\ngas_df = pre.get_Fred_data('PNGASEUUSDM',2014,2024)\nwheat_df = pre.get_Fred_data('PWHEAMTUSDM',2014,2024)\nammonia_df = pre.get_Fred_data('WPU0652013A',2014,2024)\nelec_df = pre.clean_elec_csv('Data_flat_files/ELECTRICITY_03_2024.csv',2014,2024)\n\ndf = pre.clean_pred_price_evo_csv(\"Data_flat_files/Dataset_Future_Predicting_Price_Evolutions_202403.csv\",2014,2023)\n\ntarget = 'acid'.lower()\n\nRM_codes = ['RM01/0001','RM01/0004','RM01/0006','RM01/0007']\n\nexternal_drivers = {\n    \"PNGASEUUSDM\": gas_df,\n    \"PWHEAMTUSDM\": wheat_df,\n    \"WPU0652013A\": ammonia_df,\n    \"Electricity\": elec_df\n}\n\ntest_periods = [\n    ('2020-01-01', '2020-07-01'),\n    ('2020-07-01', '2021-01-01'),\n    ('2021-01-01', '2021-07-01'),\n    ('2021-07-01', '2022-01-01'),\n    ('2022-01-01', '2022-07-01'),\n    ('2022-07-01', '2023-01-01'),\n    ('2023-01-01', '2023-07-01'),\n    ('2023-07-01', '2024-01-01')\n]\n\nlags = [1,3,6]"},"cell_type":"code","id":"a237c9c8-84da-4d31-ab1f-5b3f6176e081","outputs":[],"execution_count":2},{"source":"# Impute raw data of target variables \nimputed_df, missing = pre.impute_pred_price_evo_csv(df)\n\n# Feature engineering\ndummy_df = pre.get_dummies_and_average_price(imputed_df,target,*RM_codes)\nfeature_df = pre.generate_features(1,12,dummy_df,*RM_codes, **external_drivers)\n\nif type(feature_df.Time) != \"datetime64\":\n    feature_df['Time'] = pd.to_datetime(feature_df['Time'])\n\nassert feature_df['Time'].dtype == \"datetime64[ns]\" , \"df[Time] is not dataetime64.\"\n\nfeature_df = feature_df[feature_df.Year >= 2016]","metadata":{"executionCancelledAt":null,"executionTime":447,"lastExecutedAt":1715012973499,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Impute raw data of target variables \nimputed_df, missing = pre.impute_pred_price_evo_csv(df)\n\n# Feature engineering\ndummy_df = pre.get_dummies_and_average_price(imputed_df,target,*RM_codes)\nfeature_df = pre.generate_features(1,12,dummy_df,*RM_codes, **external_drivers)\n\nif type(feature_df.Time) != \"datetime64\":\n    feature_df['Time'] = pd.to_datetime(feature_df['Time'])\n\nassert feature_df['Time'].dtype == \"datetime64[ns]\" , \"df[Time] is not dataetime64.\"\n\nfeature_df = feature_df[feature_df.Year >= 2016]","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"cell_type":"code","id":"3db05cf2-18ba-4d25-915c-3ff47bc4e052","outputs":[],"execution_count":3},{"source":"def train_model_AR(raw_df:pd.DataFrame, code:str, lag:int, test_periods):\n    assert not len(raw_df) == 0, \"df is empty!\"\n    assert not len(code) == 0, \"RM_codes are missed.\"\n    assert isinstance(lag, int), \"Time lag is missed.\"\n    assert len(test_periods) == 2, \"There should only be one test_start and one test_end.\" \n\n    df = raw_df[raw_df[code]==True]\n    test_start, test_end = test_periods\n    # Split data into train and test sets\n    train_df = df[df.Time < test_start]\n    test_df = df[df.Time.between(test_start, test_end, inclusive = \"left\")]\n\n    X_train = train_df.filter(regex='^AR_')\n    X_test = test_df.filter(regex='^AR_')\n\n    if lag > 1:\n        conditions = tuple((f\"_{i}\" for i in range(1,lag)))\n        assert_con = tuple((f\"_{i}$\" for i in range(1,lag)))\n        X_train = X_train.loc[:,~X_train.columns.str.endswith(conditions)]\n        X_test = X_test.loc[:,~X_test.columns.str.endswith(conditions)]\n        assert not X_train.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_train not filtered correctly\"\n        assert not X_test.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_test not filtered correctly\"\n\n    y_train = train_df['Average_price'].values\n    y_test = test_df['Average_price'].values\n\n    # Standardlisation\n    scaler_x = StandardScaler()\n    X_train_scaled = scaler_x.fit_transform(X_train)\n    X_test_scaled = scaler_x.transform(X_test)\n\n    scaler_y = StandardScaler()\n    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n    y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n\n    # Define the parameter grid\n    param_grid = {'alpha': np.linspace(0.0000001, 1, 3000)}\n    # Create a Lasso regression model\n    lasso = Lasso()\n    # Create RandomizedSearchCV object\n    random_search = RandomizedSearchCV(estimator=lasso,\n                                       param_distributions=param_grid,\n                                       n_iter=300,\n                                       cv=5,\n                                       random_state=42)\n    # Fit the data to perform a grid search\n    random_search.fit(X_train_scaled, y_train_scaled)\n    assert random_search.n_features_in_ == len(X_train.columns)\n\n    # Get the best Lasso model from RandomizedSearchCV\n    best_lasso_model = random_search.best_estimator_\n    # Predict on the test data\n    y_pred_test = best_lasso_model.predict(X_test_scaled)\n    y_pred_test_inverse = scaler_y.inverse_transform(y_pred_test.reshape(-1,1))\n    mape = mean_absolute_percentage_error(y_test,y_pred_test_inverse)\n    return mape\n","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1715012973556,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def train_model_AR(raw_df:pd.DataFrame, code:str, lag:int, test_periods):\n    assert not len(raw_df) == 0, \"df is empty!\"\n    assert not len(code) == 0, \"RM_codes are missed.\"\n    assert isinstance(lag, int), \"Time lag is missed.\"\n    assert len(test_periods) == 2, \"There should only be one test_start and one test_end.\" \n\n    df = raw_df[raw_df[code]==True]\n    test_start, test_end = test_periods\n    # Split data into train and test sets\n    train_df = df[df.Time < test_start]\n    test_df = df[df.Time.between(test_start, test_end, inclusive = \"left\")]\n\n    X_train = train_df.filter(regex='^AR_')\n    X_test = test_df.filter(regex='^AR_')\n\n    if lag > 1:\n        conditions = tuple((f\"_{i}\" for i in range(1,lag)))\n        assert_con = tuple((f\"_{i}$\" for i in range(1,lag)))\n        X_train = X_train.loc[:,~X_train.columns.str.endswith(conditions)]\n        X_test = X_test.loc[:,~X_test.columns.str.endswith(conditions)]\n        assert not X_train.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_train not filtered correctly\"\n        assert not X_test.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_test not filtered correctly\"\n\n    y_train = train_df['Average_price'].values\n    y_test = test_df['Average_price'].values\n\n    # Standardlisation\n    scaler_x = StandardScaler()\n    X_train_scaled = scaler_x.fit_transform(X_train)\n    X_test_scaled = scaler_x.transform(X_test)\n\n    scaler_y = StandardScaler()\n    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n    y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n\n    # Define the parameter grid\n    param_grid = {'alpha': np.linspace(0.0000001, 1, 3000)}\n    # Create a Lasso regression model\n    lasso = Lasso()\n    # Create RandomizedSearchCV object\n    random_search = RandomizedSearchCV(estimator=lasso,\n                                       param_distributions=param_grid,\n                                       n_iter=300,\n                                       cv=5,\n                                       random_state=42)\n    # Fit the data to perform a grid search\n    random_search.fit(X_train_scaled, y_train_scaled)\n    assert random_search.n_features_in_ == len(X_train.columns)\n\n    # Get the best Lasso model from RandomizedSearchCV\n    best_lasso_model = random_search.best_estimator_\n    # Predict on the test data\n    y_pred_test = best_lasso_model.predict(X_test_scaled)\n    y_pred_test_inverse = scaler_y.inverse_transform(y_pred_test.reshape(-1,1))\n    mape = mean_absolute_percentage_error(y_test,y_pred_test_inverse)\n    return mape\n","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"cell_type":"code","id":"51285d16-a76b-4e1b-a397-3981ccaa47d3","outputs":[],"execution_count":4},{"source":"for code in RM_codes:\n    for lag in lags:\n        mape_values = list()\n        for period in test_periods:\n            result = train_model_AR(feature_df,code,lag,period)\n            mape_values.append(result)\n        average_mape = np.mean(mape_values)\n        print(f\"{target} {code}, {lag}-month lag average MAPE, AR: {average_mape:.3f}\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":269,"type":"stream"}}},"cell_type":"code","id":"2e628cd6-50b1-4cd4-8eb5-c4792da88faa","outputs":[{"output_type":"stream","name":"stdout","text":"acid RM01/0001, 1-month lag average MAPE, AR: 0.057\nacid RM01/0001, 3-month lag average MAPE, AR: 0.147\nacid RM01/0001, 6-month lag average MAPE, AR: 0.266\nacid RM01/0004, 1-month lag average MAPE, AR: 0.101\nacid RM01/0004, 3-month lag average MAPE, AR: 0.162\nacid RM01/0004, 6-month lag average MAPE, AR: 0.251\nacid RM01/0006, 1-month lag average MAPE, AR: 0.109\nacid RM01/0006, 3-month lag average MAPE, AR: 0.187\nacid RM01/0006, 6-month lag average MAPE, AR: 0.264\nacid RM01/0007, 1-month lag average MAPE, AR: 0.171\nacid RM01/0007, 3-month lag average MAPE, AR: 0.237\nacid RM01/0007, 6-month lag average MAPE, AR: 0.302\n"}],"execution_count":5},{"source":"def train_model_all_features(raw_df:pd.DataFrame, code:str, lag:int, test_periods):\n    assert not len(raw_df) == 0, \"df is empty!\"\n    assert not len(code) == 0, \"RM_codes are missed.\"\n    assert isinstance(lag, int), \"Time lag is missed.\"\n    assert len(test_periods) == 2, \"There should only be one test_start and one test_end.\" \n\n    df = raw_df[raw_df[code]==True]\n    df = df.loc[:,~df.columns.str.startswith(\"RM\")]\n    \n    test_start, test_end = test_periods\n    # Split data into train and test sets\n    train_df = df[df.Time < test_start]\n    test_df = df[df.Time.between(test_start, test_end, inclusive = \"left\")]\n\n    X_train = train_df.drop(['Time', 'Group Description', 'Year','Month','Average_price'],axis=1)\n    X_test = test_df.drop(['Time', 'Group Description', 'Year','Month','Average_price'],axis=1)\n   \n\n    if lag > 1:\n        conditions = tuple((f\"_{i}\" for i in range(1,lag)))\n        assert_con = tuple((f\"_{i}$\" for i in range(1,lag)))\n        X_train = X_train.loc[:,~X_train.columns.str.endswith(conditions)]\n        X_test = X_test.loc[:,~X_test.columns.str.endswith(conditions)]\n        assert not X_train.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_train not filtered correctly\"\n        assert not X_test.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_test not filtered correctly\"\n    \n    y_train = train_df['Average_price'].values\n    y_test = test_df['Average_price'].values\n\n    # Standardlisation\n    scaler_x = StandardScaler()\n    X_train_scaled = scaler_x.fit_transform(X_train)\n    X_test_scaled = scaler_x.transform(X_test)\n\n    scaler_y = StandardScaler()\n    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n    y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n\n    # Define the parameter grid\n    param_grid = {'alpha': np.linspace(0.0000001, 1, 3000)}\n    # Create a Lasso regression model\n    lasso = Lasso()\n    # Create RandomizedSearchCV object\n    random_search = RandomizedSearchCV(estimator=lasso,\n                                       param_distributions=param_grid,\n                                       n_iter=300,\n                                       cv=5,\n                                       random_state=42)\n    # Fit the data to perform a grid search\n    random_search.fit(X_train_scaled, y_train_scaled)\n    assert random_search.n_features_in_ == len(X_train.columns)\n\n    # Get the best Lasso model from RandomizedSearchCV\n    best_lasso_model = random_search.best_estimator_\n    # Predict on the test data\n    y_pred_test = best_lasso_model.predict(X_test_scaled)\n    y_pred_test_inverse = scaler_y.inverse_transform(y_pred_test.reshape(-1,1))\n    mape = mean_absolute_percentage_error(y_test,y_pred_test_inverse)\n    return mape\n","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1715013169124,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def train_model_all_features(raw_df:pd.DataFrame, code:str, lag:int, test_periods):\n    assert not len(raw_df) == 0, \"df is empty!\"\n    assert not len(code) == 0, \"RM_codes are missed.\"\n    assert isinstance(lag, int), \"Time lag is missed.\"\n    assert len(test_periods) == 2, \"There should only be one test_start and one test_end.\" \n\n    df = raw_df[raw_df[code]==True]\n    df = df.loc[:,~df.columns.str.startswith(\"RM\")]\n    \n    test_start, test_end = test_periods\n    # Split data into train and test sets\n    train_df = df[df.Time < test_start]\n    test_df = df[df.Time.between(test_start, test_end, inclusive = \"left\")]\n\n    X_train = train_df.drop(['Time', 'Group Description', 'Year','Month','Average_price'],axis=1)\n    X_test = test_df.drop(['Time', 'Group Description', 'Year','Month','Average_price'],axis=1)\n   \n\n    if lag > 1:\n        conditions = tuple((f\"_{i}\" for i in range(1,lag)))\n        assert_con = tuple((f\"_{i}$\" for i in range(1,lag)))\n        X_train = X_train.loc[:,~X_train.columns.str.endswith(conditions)]\n        X_test = X_test.loc[:,~X_test.columns.str.endswith(conditions)]\n        assert not X_train.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_train not filtered correctly\"\n        assert not X_test.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_test not filtered correctly\"\n    \n    y_train = train_df['Average_price'].values\n    y_test = test_df['Average_price'].values\n\n    # Standardlisation\n    scaler_x = StandardScaler()\n    X_train_scaled = scaler_x.fit_transform(X_train)\n    X_test_scaled = scaler_x.transform(X_test)\n\n    scaler_y = StandardScaler()\n    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n    y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n\n    # Define the parameter grid\n    param_grid = {'alpha': np.linspace(0.0000001, 1, 3000)}\n    # Create a Lasso regression model\n    lasso = Lasso()\n    # Create RandomizedSearchCV object\n    random_search = RandomizedSearchCV(estimator=lasso,\n                                       param_distributions=param_grid,\n                                       n_iter=300,\n                                       cv=5,\n                                       random_state=42)\n    # Fit the data to perform a grid search\n    random_search.fit(X_train_scaled, y_train_scaled)\n    assert random_search.n_features_in_ == len(X_train.columns)\n\n    # Get the best Lasso model from RandomizedSearchCV\n    best_lasso_model = random_search.best_estimator_\n    # Predict on the test data\n    y_pred_test = best_lasso_model.predict(X_test_scaled)\n    y_pred_test_inverse = scaler_y.inverse_transform(y_pred_test.reshape(-1,1))\n    mape = mean_absolute_percentage_error(y_test,y_pred_test_inverse)\n    return mape\n","outputsMetadata":{"0":{"height":38,"type":"stream"}}},"cell_type":"code","id":"68771db4-8c73-4a63-a387-56b9ef9966cb","outputs":[],"execution_count":6},{"source":"for code in RM_codes:\n    for lag in lags:\n        mape_values = list()\n        for period in test_periods:\n            result = train_model_all_features(feature_df,code,lag,period)\n            mape_values.append(result)\n        average_mape = np.mean(mape_values)\n        print(f\"{target} {code}, {lag}-month lag average MAPE, all: {average_mape:.3f}\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":269,"type":"stream"}}},"cell_type":"code","id":"1ee040e0-cba0-4816-8541-92ae9c97eb1c","outputs":[{"output_type":"stream","name":"stdout","text":"acid RM01/0001, 1-month lag average MAPE, all: 0.058\nacid RM01/0001, 3-month lag average MAPE, all: 0.112\nacid RM01/0001, 6-month lag average MAPE, all: 0.212\nacid RM01/0004, 1-month lag average MAPE, all: 0.126\nacid RM01/0004, 3-month lag average MAPE, all: 0.203\nacid RM01/0004, 6-month lag average MAPE, all: 0.338\nacid RM01/0006, 1-month lag average MAPE, all: 0.155\nacid RM01/0006, 3-month lag average MAPE, all: 0.192\nacid RM01/0006, 6-month lag average MAPE, all: 0.217\nacid RM01/0007, 1-month lag average MAPE, all: 0.166\nacid RM01/0007, 3-month lag average MAPE, all: 0.189\nacid RM01/0007, 6-month lag average MAPE, all: 0.187\n"}],"execution_count":7}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}