{"cells":[{"cell_type":"markdown","id":"a62679b9-b669-4eb6-859d-fdfbee54ba8f","metadata":{},"source":["# Test_Acid_AR"]},{"cell_type":"code","execution_count":null,"id":"470a342d-66ac-46e2-a8e6-bc5a976d1e81","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":5760,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1715011554441,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install fredapi","outputsMetadata":{"0":{"height":353,"type":"stream"}}},"outputs":[],"source":["!pip install fredapi"]},{"cell_type":"code","execution_count":6,"id":"a237c9c8-84da-4d31-ab1f-5b3f6176e081","metadata":{"executionCancelledAt":null,"executionTime":4403,"lastExecutedAt":1715011799498,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import preprocessor as pre\nimport visualiser as visual\nimport pandas as pd\nfrom sklearn.linear_model import Lasso, LinearRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n## Preparations\n# Import data\ngas_df = pre.get_Fred_data('PNGASEUUSDM',2014,2024)\nwheat_df = pre.get_Fred_data('PWHEAMTUSDM',2014,2024)\nammonia_df = pre.get_Fred_data('WPU0652013A',2014,2024)\nelec_df = pre.clean_elec_csv('Data_flat_files/ELECTRICITY_03_2024.csv',2014,2024)\n\ndf = pre.clean_pred_price_evo_csv(\"Data_flat_files/Dataset_Future_Predicting_Price_Evolutions_202403.csv\",2014,2023)\n\ntarget = 'acid'.lower()\n\nRM_codes = ['RM01/0001','RM01/0004','RM01/0006','RM01/0007']\n\nexternal_drivers = {\n    \"PNGASEUUSDM\": gas_df,\n    \"PWHEAMTUSDM\": wheat_df,\n    \"WPU0652013A\": ammonia_df,\n    \"Electricity\": elec_df\n}\n\ntest_periods = [\n    ('2020-01-01', '2020-07-01'),\n    ('2020-07-01', '2021-01-01'),\n    ('2021-01-01', '2021-07-01'),\n    ('2021-07-01', '2022-01-01'),\n    ('2022-01-01', '2022-07-01'),\n    ('2022-07-01', '2023-01-01'),\n    ('2023-01-01', '2023-07-01'),\n    ('2023-07-01', '2024-01-01')\n]\n\nlags = [1,3,6]"},"outputs":[],"source":["import preprocessor as pre\n","import visualiser as visual\n","import pandas as pd\n","from sklearn.linear_model import Lasso, LinearRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV\n","from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","## Preparations\n","# Import data\n","gas_df = pre.get_Fred_data('PNGASEUUSDM',2014,2024)\n","wheat_df = pre.get_Fred_data('PWHEAMTUSDM',2014,2024)\n","ammonia_df = pre.get_Fred_data('WPU0652013A',2014,2024)\n","elec_df = pre.clean_elec_csv('Data_flat_files/ELECTRICITY_03_2024.csv',2014,2024)\n","\n","df = pre.clean_pred_price_evo_csv(\"Data_flat_files/Dataset_Future_Predicting_Price_Evolutions_202403.csv\",2014,2023)\n","\n","target = 'acid'.lower()\n","\n","RM_codes = ['RM01/0001','RM01/0004','RM01/0006','RM01/0007']\n","\n","external_drivers = {\n","    \"PNGASEUUSDM\": gas_df,\n","    \"PWHEAMTUSDM\": wheat_df,\n","    \"WPU0652013A\": ammonia_df,\n","    \"Electricity\": elec_df\n","}\n","\n","test_periods = [\n","    ('2020-01-01', '2020-07-01'),\n","    ('2020-07-01', '2021-01-01'),\n","    ('2021-01-01', '2021-07-01'),\n","    ('2021-07-01', '2022-01-01'),\n","    ('2022-01-01', '2022-07-01'),\n","    ('2022-07-01', '2023-01-01'),\n","    ('2023-01-01', '2023-07-01'),\n","    ('2023-07-01', '2024-01-01')\n","]\n","\n","lags = [1,3,6]"]},{"cell_type":"code","execution_count":3,"id":"3db05cf2-18ba-4d25-915c-3ff47bc4e052","metadata":{"executionCancelledAt":null,"executionTime":477,"lastExecutedAt":1715011557223,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Impute raw data of target variables \nimputed_df, missing = pre.impute_pred_price_evo_csv(df)\n\n# Feature engineering\ndummy_df = pre.get_dummies_and_average_price(imputed_df,target,*RM_codes)\ntemp_df = pre.generate_features(1,12,dummy_df,*RM_codes, **external_drivers)\nfeature_df = pre.get_interaction_terms(temp_df)\n\nif type(feature_df.Time) != \"datetime64\":\n    feature_df['Time'] = pd.to_datetime(feature_df['Time'])\n\nassert feature_df['Time'].dtype == \"datetime64[ns]\" , \"df[Time] is not dataetime64.\"\n\nfeature_df = feature_df[feature_df.Year >= 2016]","outputsMetadata":{"0":{"height":143,"type":"stream"}}},"outputs":[],"source":["# Impute raw data of target variables \n","imputed_df, missing = pre.impute_pred_price_evo_csv(df)\n","\n","# Feature engineering\n","dummy_df = pre.get_dummies_and_average_price(imputed_df,target,*RM_codes)\n","temp_df = pre.generate_features(1,12,dummy_df,*RM_codes, **external_drivers)\n","feature_df = pre.get_interaction_terms(temp_df)\n","\n","if type(feature_df.Time) != \"datetime64\":\n","    feature_df['Time'] = pd.to_datetime(feature_df['Time'])\n","\n","assert feature_df['Time'].dtype == \"datetime64[ns]\" , \"df[Time] is not dataetime64.\"\n","\n","feature_df = feature_df[feature_df.Year >= 2016]"]},{"cell_type":"code","execution_count":4,"id":"51285d16-a76b-4e1b-a397-3981ccaa47d3","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1715011557276,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def train_model_AR(raw_df:pd.DataFrame, code:str, lag:int, test_periods):\n    assert not len(raw_df) == 0, \"df is empty!\"\n    assert not len(code) == 0, \"RM_codes are missed.\"\n    assert isinstance(lag, int), \"Time lag is missed.\"\n    assert len(test_periods) == 2, \"There should only be one test_start and one test_end.\" \n\n    df = raw_df[raw_df[code]==True]\n    test_start, test_end = test_periods\n    # Split data into train and test sets\n    train_df = df[df.Time < test_start]\n    test_df = df[df.Time.between(test_start, test_end, inclusive = \"left\")]\n\n    X_train = train_df.filter(regex='^AR_')\n    X_test = test_df.filter(regex='^AR_')\n\n    if lag > 1:\n        conditions = tuple((f\"_{i}\" for i in range(1,lag)))\n        assert_con = tuple((f\"_{i}$\" for i in range(1,lag)))\n        X_train = X_train.loc[:,~X_train.columns.str.endswith(conditions)]\n        X_test = X_test.loc[:,~X_test.columns.str.endswith(conditions)]\n        assert not X_train.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_train not filtered correctly\"\n        assert not X_test.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_test not filtered correctly\"\n\n    y_train = train_df['Average_price'].values\n    y_test = test_df['Average_price'].values\n\n    # Standardlisation\n    scaler_x = StandardScaler()\n    X_train_scaled = scaler_x.fit_transform(X_train)\n    X_test_scaled = scaler_x.transform(X_test)\n\n    scaler_y = StandardScaler()\n    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n    y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n\n    # Define the parameter grid\n    param_grid = {'alpha': np.linspace(0.0000001, 1, 3000)}\n    # Create a Lasso regression model\n    lasso = Lasso()\n    # Create RandomizedSearchCV object\n    random_search = RandomizedSearchCV(estimator=lasso,\n                                       param_distributions=param_grid,\n                                       n_iter=300,\n                                       cv=5,\n                                       random_state=42)\n    # Fit the data to perform a grid search\n    random_search.fit(X_train_scaled, y_train_scaled)\n    assert random_search.n_features_in_ == len(X_train.columns)\n\n    # Get the best Lasso model from RandomizedSearchCV\n    best_lasso_model = random_search.best_estimator_\n    # Predict on the test data\n    y_pred_test = best_lasso_model.predict(X_test_scaled)\n    y_pred_test_inverse = scaler_y.inverse_transform(y_pred_test.reshape(-1,1))\n    mape = mean_absolute_percentage_error(y_test,y_pred_test_inverse)\n    return mape\n","outputsMetadata":{"0":{"height":101,"type":"stream"}}},"outputs":[],"source":["def train_model_AR(raw_df:pd.DataFrame, code:str, lag:int, test_periods):\n","    assert not len(raw_df) == 0, \"df is empty!\"\n","    assert not len(code) == 0, \"RM_codes are missed.\"\n","    assert isinstance(lag, int), \"Time lag is missed.\"\n","    assert len(test_periods) == 2, \"There should only be one test_start and one test_end.\" \n","\n","    df = raw_df[raw_df[code]==True]\n","    test_start, test_end = test_periods\n","    # Split data into train and test sets\n","    train_df = df[df.Time < test_start]\n","    test_df = df[df.Time.between(test_start, test_end, inclusive = \"left\")]\n","\n","    X_train = train_df.filter(regex='^AR_')\n","    X_test = test_df.filter(regex='^AR_')\n","\n","    if lag > 1:\n","        conditions = tuple((f\"_{i}\" for i in range(1,lag)))\n","        assert_con = tuple((f\"_{i}$\" for i in range(1,lag)))\n","        X_train = X_train.loc[:,~X_train.columns.str.endswith(conditions)]\n","        X_test = X_test.loc[:,~X_test.columns.str.endswith(conditions)]\n","        assert not X_train.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_train not filtered correctly\"\n","        assert not X_test.filter(regex='|'.join(assert_con)).any(axis=1).any(), \"X_test not filtered correctly\"\n","\n","    y_train = train_df['Average_price'].values\n","    y_test = test_df['Average_price'].values\n","\n","    # Standardlisation\n","    scaler_x = StandardScaler()\n","    X_train_scaled = scaler_x.fit_transform(X_train)\n","    X_test_scaled = scaler_x.transform(X_test)\n","\n","    scaler_y = StandardScaler()\n","    y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1,1))\n","    y_test_scaled = scaler_y.transform(y_test.reshape(-1,1))\n","\n","    # Define the parameter grid\n","    param_grid = {'alpha': np.linspace(0.0000001, 1, 3000)}\n","    # Create a Lasso regression model\n","    lasso = Lasso()\n","    # Create RandomizedSearchCV object\n","    random_search = RandomizedSearchCV(estimator=lasso,\n","                                       param_distributions=param_grid,\n","                                       n_iter=300,\n","                                       cv=5,\n","                                       random_state=42)\n","    # Fit the data to perform a grid search\n","    random_search.fit(X_train_scaled, y_train_scaled)\n","    assert random_search.n_features_in_ == len(X_train.columns)\n","\n","    # Get the best Lasso model from RandomizedSearchCV\n","    best_lasso_model = random_search.best_estimator_\n","    # Predict on the test data\n","    y_pred_test = best_lasso_model.predict(X_test_scaled)\n","    y_pred_test_inverse = scaler_y.inverse_transform(y_pred_test.reshape(-1,1))\n","    mape = mean_absolute_percentage_error(y_test,y_pred_test_inverse)\n","    return mape\n"]},{"cell_type":"code","execution_count":5,"id":"2e628cd6-50b1-4cd4-8eb5-c4792da88faa","metadata":{"executionCancelledAt":null,"executionTime":193811,"lastExecutedAt":1715011751087,"lastExecutedByKernel":"ecf3592b-e56d-4adf-8d4b-fad47b54a7e4","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"for code in RM_codes:\n    for lag in lags:\n        mape_values = list()\n        for period in test_periods:\n            result = train_model_AR(feature_df,code,lag,period)\n            mape_values.append(result)\n        average_mape = np.mean(mape_values)\n        print(f\"{target} {code}, {lag}-month lag average MAPE, AR: {average_mape:.3f}\")","outputsMetadata":{"0":{"height":248,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["acid RM01/0001, 1-month lag average MAPE, AR: 0.057\n","acid RM01/0001, 3-month lag average MAPE, AR: 0.147\n","acid RM01/0001, 6-month lag average MAPE, AR: 0.266\n","acid RM01/0004, 1-month lag average MAPE, AR: 0.101\n","acid RM01/0004, 3-month lag average MAPE, AR: 0.162\n","acid RM01/0004, 6-month lag average MAPE, AR: 0.251\n","acid RM01/0006, 1-month lag average MAPE, AR: 0.109\n","acid RM01/0006, 3-month lag average MAPE, AR: 0.187\n","acid RM01/0006, 6-month lag average MAPE, AR: 0.264\n","acid RM01/0007, 1-month lag average MAPE, AR: 0.171\n","acid RM01/0007, 3-month lag average MAPE, AR: 0.237\n","acid RM01/0007, 6-month lag average MAPE, AR: 0.302\n"]}],"source":["for code in RM_codes:\n","    for lag in lags:\n","        mape_values = list()\n","        for period in test_periods:\n","            result = train_model_AR(feature_df,code,lag,period)\n","            mape_values.append(result)\n","        average_mape = np.mean(mape_values)\n","        print(f\"{target} {code}, {lag}-month lag average MAPE, AR: {average_mape:.3f}\")"]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
